{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from datasets import keepcontrol\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tcn import TCN, tcn_full_summary\n",
    "from utils.losses import MyWeightedBinaryCrossentropy\n",
    "from utils.evaluate import compare_events\n",
    "from scipy.signal import find_peaks\n",
    "from utils.data_utils import select_data, get_gait_events, get_labels\n",
    "from utils.preprocessing import resamp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "PATH = \"/mnt/neurogeriatrics_data/Keep Control/Data/lab dataset/rawdata\" if sys.platform == \"linux\" else \"Z:\\\\Keep Control\\\\Data\\\\lab dataset\\\\rawdata\"\n",
    "DEMOGRAPHICS_FILE = \"/mnt/neurogeriatrics_data/Keep Control/Data/lab dataset/rawdata/participants.tsv\" if sys.platform == \"linux\" else \"Z:\\\\Keep Control\\\\Data\\\\lab dataset\\\\rawdata\\\\participants.tsv\"\n",
    "TRACKED_POINTS = [\"left_ankle\", \"right_ankle\"]\n",
    "CLASSIFICATION_TASK = \"events\"\n",
    "WIN_LEN = 400\n",
    "DERIVATIVES_PATH = os.path.join(os.path.split(PATH)[0], \"derivatives\", \"motion\", \"doe\")\n",
    "CHECKPOINT_FILEPATH = os.path.join(os.path.split(PATH)[0], \"derivatives\", \"motion\", \"doe\", \"models\")\n",
    "\n",
    "# TODO: should be inferred from data\n",
    "INPUT_SHAPE = (None, 6)\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset from pickle ...\n"
     ]
    }
   ],
   "source": [
    "ds_train, ds_val, ds_test = keepcontrol.load_data(\n",
    "    path=PATH,\n",
    "    filename=DEMOGRAPHICS_FILE,\n",
    "    tracked_points=TRACKED_POINTS,\n",
    "    incl_magn=False,\n",
    "    classification_task=CLASSIFICATION_TASK,\n",
    "    win_len=WIN_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model, set compile=False because custom loss cannot be loaded\n",
    "tcn_model = keras.models.load_model(CHECKPOINT_FILEPATH, compile=False)\n",
    "\n",
    "# Compile the model, using same as before\n",
    "LOSSES, METRICS = {}, {}\n",
    "for i in range(NUM_CLASSES):\n",
    "    LOSSES[f\"outputs_{i+1}\"] = MyWeightedBinaryCrossentropy()\n",
    "    METRICS[f\"outputs_{i+1}\"] = keras.metrics.BinaryAccuracy()\n",
    "tcn_model.compile(loss=LOSSES, optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output variables\n",
    "out_sub_ids = []\n",
    "out_filenames = []\n",
    "out_event_types = []\n",
    "out_reference_timings = []\n",
    "out_predicted_timings = []\n",
    "\n",
    "test_ids = ds_test\n",
    "for (i_sub_id, sub_id) in enumerate(test_ids[30:40]):    \n",
    "    test_filenames = [fname for fname in os.listdir(os.path.join(PATH, sub_id, \"motion\")) if (fname.endswith(\"_events.tsv\")) and (\"_task-walk\" in fname)]\n",
    "    \n",
    "    for (i_test_filename, test_filename) in enumerate(test_filenames):\n",
    "        \n",
    "        # Load the IMU motion and channels files\n",
    "        df_imu = pd.read_csv(\n",
    "            os.path.join(PATH, sub_id, \"motion\", test_filename.replace(\"_events.tsv\", \"_tracksys-imu_motion.tsv\")), \n",
    "            sep=\"\\t\", \n",
    "            header=0\n",
    "        )\n",
    "        df_imu_channels = pd.read_csv(\n",
    "            os.path.join(PATH, sub_id, \"motion\", test_filename.replace(\"_events.tsv\", \"_tracksys-imu_channels.tsv\")), \n",
    "            sep=\"\\t\", \n",
    "            header=0\n",
    "        )\n",
    "        \n",
    "        # Resample if necessary\n",
    "        if df_imu_channels[\"sampling_frequency\"].iloc[0] != 200:\n",
    "            X = df_imu.to_numpy()\n",
    "            X = resamp1d(X, df_imu_channels[\"sampling_frequency\"].iloc[0], 200)\n",
    "            df_imu = pd.DataFrame(data=X, columns=df_imu.columns)\n",
    "            del X\n",
    "        \n",
    "        # Select data from given tracked points\n",
    "        df_select = select_data(df_imu, df_imu_channels, tracked_points=TRACKED_POINTS, incl_magn=False)\n",
    "        \n",
    "        # Determine start and end of current task trial\n",
    "        df_events = pd.read_csv(os.path.join(PATH, sub_id, \"motion\", test_filename), sep=\"\\t\", header=0)\n",
    "        indx_start = df_events[df_events[\"event_type\"]==\"start\"][\"onset\"].values[0] - 1\n",
    "        indx_stop = df_events[df_events[\"event_type\"]==\"stop\"][\"onset\"].values[0]\n",
    "        df_events = df_events.loc[(df_events[\"onset\"]>=indx_start) & (df_events[\"onset\"]<=indx_stop)]\n",
    "        df_select = df_select.iloc[indx_start:indx_stop]\n",
    "        \n",
    "        # Normalize\n",
    "        normalize = True\n",
    "        if normalize:\n",
    "            df_select = ( df_select - df_select.mean() ) / df_select.std()\n",
    "        \n",
    "        # Get indices corresponding to gait events\n",
    "        events = get_gait_events(df_events=df_events)\n",
    "        \n",
    "        # Get labels\n",
    "        labels = get_labels(len(df_select), events, classification_task=CLASSIFICATION_TASK)\n",
    "        \n",
    "        # Convert data to numpy array\n",
    "        data = df_select.to_numpy()\n",
    "        \n",
    "        # Split left/right\n",
    "        data = np.stack([data[:,:data.shape[-1]//len(TRACKED_POINTS)], data[:,data.shape[-1]//len(TRACKED_POINTS):]], axis=0)\n",
    "        labels = np.stack([labels[:,:labels.shape[-1]//len(TRACKED_POINTS)], labels[:,labels.shape[-1]//len(TRACKED_POINTS):]], axis=0)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = tcn_model.predict(data)\n",
    "        \n",
    "        # Get indices from annotated and predicted events\n",
    "        ix_true_ICL = np.argwhere(labels[0][:,0]==1)[:,0]\n",
    "        ix_true_FCL = np.argwhere(labels[0][:,1]==1)[:,0]\n",
    "        ix_true_ICR = np.argwhere(labels[1][:,0]==1)[:,0]\n",
    "        ix_true_FCR = np.argwhere(labels[1][:,1]==1)[:,0]\n",
    "\n",
    "        ix_pred_ICL, pk_props_ICL = find_peaks(predictions[0][0][:,0], height=0.5, distance=50)\n",
    "        ix_pred_FCL, pk_props_FCL = find_peaks(predictions[1][0][:,0], height=0.5, distance=50)\n",
    "        ix_pred_ICR, pk_props_ICR = find_peaks(predictions[0][1][:,0], height=0.5, distance=50)\n",
    "        ix_pred_FCR, pk_props_FCR = find_peaks(predictions[1][1][:,0], height=0.5, distance=50)\n",
    "        \n",
    "        # For each gait event, determine the time error\n",
    "        ann2pred_ICL, pred2ann_ICL, time_difference_ICL = compare_events(ix_true_ICL, ix_pred_ICL)\n",
    "        ann2pred_FCL, pred2ann_FCL, time_difference_FCL = compare_events(ix_true_FCL, ix_pred_FCL)\n",
    "        ann2pred_ICR, pred2ann_ICR, time_difference_ICR = compare_events(ix_true_ICR, ix_pred_ICR)\n",
    "        ann2pred_FCR, pred2ann_FCR, time_difference_FCR = compare_events(ix_true_FCR, ix_pred_FCR)\n",
    "        if (ann2pred_ICL is None) or (pred2ann_ICL is None):\n",
    "            continue\n",
    "        if (ann2pred_FCL is None) or (pred2ann_FCL is None):\n",
    "            continue\n",
    "        if (ann2pred_ICR is None) or (pred2ann_ICR is None):\n",
    "            continue\n",
    "        if (ann2pred_FCR is None) or (pred2ann_FCR is None):\n",
    "            continue\n",
    "        \n",
    "        # Left Initial Contacts\n",
    "        for i in range(len(ix_true_ICL)-1, -1, -1):\n",
    "            if ann2pred_ICL[i] >- 999:\n",
    "                out_predicted_timings.append(ix_pred_ICL[ann2pred_ICL[i]])\n",
    "                ix_pred_ICL = np.delete(ix_pred_ICL, ann2pred_ICL[i])\n",
    "                pred2ann_ICL = np.delete(pred2ann_ICL, ann2pred_ICL[i])\n",
    "            else:\n",
    "                out_predicted_timings.append(np.nan)\n",
    "            out_reference_timings.append(ix_true_ICL[i])\n",
    "            out_event_types.append(\"ICL\")\n",
    "            out_filenames.append(test_filename)\n",
    "            out_sub_ids.append(sub_id)\n",
    "        for i in range(len(ix_pred_ICL)-1, -1, -1):\n",
    "            if pred2ann_ICL[i] > -999:\n",
    "                out_reference_timings.append(ix_true_ICL[pred2ann_ICL[i]])\n",
    "                ix_true_ICL = np.delete(ix_true_ICL, pred2ann_ICL[i])\n",
    "                ann2pred_ICL = np.delete(ann2pred_ICL, pred2ann_ICL[i])\n",
    "            else:\n",
    "                out_reference_timings.append(np.nan)\n",
    "            out_predicted_timings.append(ix_pred_ICL[i])\n",
    "            out_event_types.append(\"ICL\")\n",
    "            out_filenames.append(test_filename)\n",
    "            out_sub_ids.append(sub_id)\n",
    "            \n",
    "        # Left Final Contacts\n",
    "        for i in range(len(ix_true_FCL)-1, -1, -1):\n",
    "            if ann2pred_FCL[i] >- 999:\n",
    "                out_predicted_timings.append(ix_pred_FCL[ann2pred_FCL[i]])\n",
    "                ix_pred_FCL = np.delete(ix_pred_FCL, ann2pred_FCL[i])\n",
    "                pred2ann_FCL = np.delete(pred2ann_FCL, ann2pred_FCL[i])\n",
    "            else:\n",
    "                out_predicted_timings.append(np.nan)\n",
    "            out_reference_timings.append(ix_true_FCL[i])\n",
    "            out_event_types.append(\"FCL\")\n",
    "            out_filenames.append(test_filename)\n",
    "            out_sub_ids.append(sub_id)\n",
    "        for i in range(len(ix_pred_FCL)-1, -1, -1):\n",
    "            if pred2ann_FCL[i] > -999:\n",
    "                out_reference_timings.append(ix_true_FCL[pred2ann_FCL[i]])\n",
    "                ix_true_FCL = np.delete(ix_true_FCL, pred2ann_FCL[i])\n",
    "                ann2pred_FCL = np.delete(ann2pred_FCL, pred2ann_FCL[i])\n",
    "            else:\n",
    "                out_reference_timings.append(np.nan)\n",
    "            out_predicted_timings.append(ix_pred_FCL[i])\n",
    "            out_event_types.append(\"FCL\")\n",
    "            out_filenames.append(test_filename)\n",
    "            out_sub_ids.append(sub_id)\n",
    "    \n",
    "        # Right Initial Contacts\n",
    "        for i in range(len(ix_true_ICR)-1, -1, -1):\n",
    "            if ann2pred_ICR[i] >- 999:\n",
    "                out_predicted_timings.append(ix_pred_ICR[ann2pred_ICR[i]])\n",
    "                ix_pred_ICR = np.delete(ix_pred_ICR, ann2pred_ICR[i])\n",
    "                pred2ann_ICR = np.delete(pred2ann_ICR, ann2pred_ICR[i])\n",
    "            else:\n",
    "                out_predicted_timings.append(np.nan)\n",
    "            out_reference_timings.append(ix_true_ICR[i])\n",
    "            out_event_types.append(\"ICR\")\n",
    "            out_filenames.append(test_filename)\n",
    "            out_sub_ids.append(sub_id)\n",
    "        for i in range(len(ix_pred_ICR)-1, -1, -1):\n",
    "            if pred2ann_ICR[i] > -999:\n",
    "                out_reference_timings.append(ix_true_ICR[pred2ann_ICR[i]])\n",
    "                ix_true_ICR = np.delete(ix_true_ICR, pred2ann_ICR[i])\n",
    "                ann2pred_ICR = np.delete(ann2pred_ICR, pred2ann_ICR[i])\n",
    "            else:\n",
    "                out_reference_timings.append(np.nan)\n",
    "            out_predicted_timings.append(ix_pred_ICR[i])\n",
    "            out_event_types.append(\"ICR\")\n",
    "            out_filenames.append(test_filename)\n",
    "            out_sub_ids.append(sub_id)\n",
    "            \n",
    "        # Right Final Contacts\n",
    "        for i in range(len(ix_true_FCR)-1, -1, -1):\n",
    "            if ann2pred_FCR[i] >- 999:\n",
    "                out_predicted_timings.append(ix_pred_FCR[ann2pred_FCR[i]])\n",
    "                ix_pred_FCR = np.delete(ix_pred_FCR, ann2pred_FCR[i])\n",
    "                pred2ann_FCR = np.delete(pred2ann_FCR, ann2pred_FCR[i])\n",
    "            else:\n",
    "                out_predicted_timings.append(np.nan)\n",
    "            out_reference_timings.append(ix_true_FCR[i])\n",
    "            out_event_types.append(\"FCR\")\n",
    "            out_filenames.append(test_filename)\n",
    "            out_sub_ids.append(sub_id)\n",
    "        for i in range(len(ix_pred_FCR)-1, -1, -1):\n",
    "            if pred2ann_FCR[i] > -999:\n",
    "                out_reference_timings.append(ix_true_FCR[pred2ann_FCR[i]])\n",
    "                ix_true_FCR = np.delete(ix_true_FCR, pred2ann_FCR[i])\n",
    "                ann2pred_FCR = np.delete(ann2pred_FCR, pred2ann_FCR[i])\n",
    "            else:\n",
    "                out_reference_timings.append(np.nan)\n",
    "            out_predicted_timings.append(ix_pred_FCR[i])\n",
    "            out_event_types.append(\"FCR\")\n",
    "            out_filenames.append(test_filename)\n",
    "            out_sub_ids.append(sub_id)\n",
    "print(f\"Cell completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 185,  436,  696,  950, 1219]), array([  56,  311,  560,  818, 1077]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_pred_FCL, ix_true_FCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub</th>\n",
       "      <th>filename</th>\n",
       "      <th>event_type</th>\n",
       "      <th>ref</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-pp156</td>\n",
       "      <td>sub-pp156_task-walkFast_events.tsv</td>\n",
       "      <td>ICL</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>1081.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-pp156</td>\n",
       "      <td>sub-pp156_task-walkFast_events.tsv</td>\n",
       "      <td>ICL</td>\n",
       "      <td>882.0</td>\n",
       "      <td>879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-pp156</td>\n",
       "      <td>sub-pp156_task-walkFast_events.tsv</td>\n",
       "      <td>ICL</td>\n",
       "      <td>700.0</td>\n",
       "      <td>697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-pp156</td>\n",
       "      <td>sub-pp156_task-walkFast_events.tsv</td>\n",
       "      <td>ICL</td>\n",
       "      <td>514.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-pp156</td>\n",
       "      <td>sub-pp156_task-walkFast_events.tsv</td>\n",
       "      <td>ICL</td>\n",
       "      <td>329.0</td>\n",
       "      <td>328.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sub                            filename event_type     ref    pred\n",
       "0  sub-pp156  sub-pp156_task-walkFast_events.tsv        ICL  1085.0  1081.0\n",
       "1  sub-pp156  sub-pp156_task-walkFast_events.tsv        ICL   882.0   879.0\n",
       "2  sub-pp156  sub-pp156_task-walkFast_events.tsv        ICL   700.0   697.0\n",
       "3  sub-pp156  sub-pp156_task-walkFast_events.tsv        ICL   514.0   512.0\n",
       "4  sub-pp156  sub-pp156_task-walkFast_events.tsv        ICL   329.0   328.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_out = pd.DataFrame({\n",
    "    \"sub\": out_sub_ids,\n",
    "    \"filename\": out_filenames,\n",
    "    \"event_type\": out_event_types,\n",
    "    \"ref\": out_reference_timings,\n",
    "    \"pred\": out_predicted_timings\n",
    "})\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out2 = pd.DataFrame({\n",
    "    \"sub\": out_sub_ids,\n",
    "    \"filename\": out_filenames,\n",
    "    \"event_type\": out_event_types,\n",
    "    \"ref\": out_reference_timings,\n",
    "    \"pred\": out_predicted_timings\n",
    "})\n",
    "df_out2.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a46f08e0b385f7b7576e4c544817319d1da98fa53d1492e7fa77b67b75acd524"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
